{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis code is reimplement of \"CVPR 2018 paper: Learning to Compare: Relation Network for Few-Shot Learning\"(Zero-shot part)\\n\\nDownload the AWA2 dataset at \"https://cvml.ist.ac.at/AwA2/\"\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code is reimplement of \"CVPR 2018 paper: Learning to Compare: Relation Network for Few-Shot Learning\"(Zero-shot part)\n",
    "\n",
    "Download the AWA2 dataset(AWA2-base.zip, AWA2-features.zip) at \"https://cvml.ist.ac.at/AwA2/\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data about animals' attribute\n",
    "class Attribute:\n",
    "    def __init__(self, root):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "            root : location of the file\n",
    "        \"\"\"\n",
    "        self.idx_to_cls = {}\n",
    "        f = open(root + \"classes.txt\", 'r')\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            self.idx_to_cls[int(line.split()[0])-1] = line.split()[1]\n",
    "        f.close()\n",
    "\n",
    "        f = open(root + \"predicate-matrix-continuous.txt\", 'r')\n",
    "        attribute=[]\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            attribute.append(list(map(float, line.split())))\n",
    "        f.close()\n",
    "        self.attribute=torch.tensor(attribute)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.attribute[idx]\n",
    "        \n",
    "#\n",
    "def load_split(root, split_num=10):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        root : location of the file\n",
    "        split_num : num of class to test\n",
    "    \"\"\"\n",
    "    print(\"Loading data starts..\")\n",
    "    #all data is data of query set\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "\n",
    "    test_cls = np.random.choice(50, split_num, replace=False)\n",
    "\n",
    "    f1 = open(root + \"AwA2-features.txt\", 'r')\n",
    "    f2 = open(root + \"AwA2-labels.txt\", 'r')\n",
    "\n",
    "    features = f1.readlines()\n",
    "    labels = f2.readlines()\n",
    "\n",
    "    for feature, label in zip(features, labels):\n",
    "        label = int(label)-1\n",
    "        if label in test_cls:\n",
    "            test_x.append(list(map(float, feature.split())))\n",
    "            test_y.append(label)\n",
    "        else:\n",
    "            train_x.append(list(map(float, feature.split())))\n",
    "            train_y.append(label)   \n",
    "    f1.close()\n",
    "    f2.close()\n",
    "\n",
    "    train_set = torch.utils.data.TensorDataset(torch.tensor(train_x), torch.LongTensor(train_y))\n",
    "    test_set = torch.utils.data.TensorDataset(torch.tensor(test_x), torch.LongTensor(test_y))\n",
    "    print(\"finish\")\n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    #Embedding module for attributes\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        layers = []\n",
    "        layers += [nn.Linear(85, 1024), nn.ReLU()] \n",
    "        layers += [nn.Linear(1024, 2048), nn.ReLU()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x(bsize*85) -> embedded feature(bsize*2048)\n",
    "        return self.layers(x)\n",
    "    \n",
    "class RelationNet(nn.Module):\n",
    "    #Relation module for concatenated features\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        layers= []\n",
    "        layers += [nn.Linear(4096, 400), nn.ReLU()]\n",
    "        layers += [nn.Linear(400, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layer = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x(bsize * cls_num * 4096) -> score(bsize * cls_num)\n",
    "        return self.layer(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(attribute, train, test, lr=0.01, EPISODE_NUM=1, bsize=32, test_bsize=32):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        attribute : attribute of the animals\n",
    "        train : train datset\n",
    "        test : test dataset\n",
    "        lr :learning rate\n",
    "        EPISODE_NUM : =~ epoch\n",
    "        bsize : batch size\n",
    "        test_bisze : batch size for test set\n",
    "    \"\"\"\n",
    "    emb = Embedding()\n",
    "    RN = RelationNet()\n",
    "    MSE = nn.MSELoss()\n",
    "\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda is on\")\n",
    "        emb.cuda()\n",
    "        RN.cuda()\n",
    "        MSE=MSE.cuda()\n",
    "    \n",
    "    emb_optim = torch.optim.Adam(emb.parameters(), lr = lr)\n",
    "    RN_optim = torch.optim.Adam(RN.parameters(), lr = lr)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=test_bsize, shuffle=True)\n",
    "        \n",
    "    for i in range(EPISODE_NUM):\n",
    "        emb.train()\n",
    "        RN.train()\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=bsize, shuffle=True)\n",
    "        train_feature, train_label = train_loader.__iter__().next()\n",
    "        if len(train_feature) != bsize:\n",
    "            bsize=len(train_feature)\n",
    "\n",
    "        #relabeling the index of training set\n",
    "        support_label={}\n",
    "        cls_num=0\n",
    "        new_label=[]\n",
    "        for label in train_label:\n",
    "            if int(label) not in support_label:\n",
    "                support_label[int(label)] = cls_num\n",
    "                cls_num += 1\n",
    "            new_label.append(support_label[int(label)])\n",
    "        train_feature = torch.autograd.Variable(train_feature)\n",
    "        support_attribute = torch.autograd.Variable(attribute[list(support_label.keys())])\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            support_attribute = support_attribute.cuda()\n",
    "            train_feature = train_feature.cuda()\n",
    "\n",
    "        att_emb = emb(support_attribute).unsqueeze(0).repeat(bsize, 1, 1)\n",
    "        train_emb = train_feature.unsqueeze(0).repeat(cls_num, 1, 1).transpose(0,1)\n",
    "\n",
    "        concat = torch.cat((att_emb, train_emb), 2)\n",
    "        score = RN(concat).squeeze(2)\n",
    "        \n",
    "        one_hot = torch.zeros(bsize, cls_num)\n",
    "        one_hot[torch.arange(bsize), new_label] = 1\n",
    "        one_hot = torch.autograd.Variable(one_hot)\n",
    "        if torch.cuda.is_available(): \n",
    "            one_hot=one_hot.cuda()\n",
    "        \n",
    "        loss = MSE(score, one_hot)\n",
    "        \n",
    "        emb.zero_grad()\n",
    "        RN.zero_grad()\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        emb_optim.step()\n",
    "        RN_optim.step()\n",
    "\n",
    "\n",
    "        if i%400 == 0 :\n",
    "            emb.eval()\n",
    "            RN.eval()\n",
    "            correct=0\n",
    "            for test_feature, test_label in test_loader:\n",
    "                if len(test_feature) != test_bsize:\n",
    "                    test_bsize=len(test_feature)\n",
    "                \n",
    "                support_label={}\n",
    "                cls_num=0\n",
    "                new_label=[]\n",
    "                \n",
    "                for label in test_label:\n",
    "                    if int(label) not in support_label:\n",
    "                        support_label[int(label)] = cls_num\n",
    "                        cls_num += 1\n",
    "                    new_label.append(support_label[int(label)])\n",
    "\n",
    "                test_feature = torch.autograd.Variable(test_feature)\n",
    "                support_attribute = torch.autograd.Variable(attribute[list(support_label.keys())])\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    support_attribute = support_attribute.cuda()\n",
    "                    test_feature = test_feature.cuda()\n",
    "\n",
    "                att_emb = emb(support_attribute).unsqueeze(0).repeat(test_bsize, 1, 1)\n",
    "                test_emb = test_feature.unsqueeze(0).repeat(cls_num, 1, 1).transpose(0,1)\n",
    "                \n",
    "                concat = torch.cat((att_emb, test_emb), 2)\n",
    "                score = RN(concat).squeeze(2)\n",
    "\n",
    "                pred = score.max(1)[1]\n",
    "                \n",
    "                new_label = torch.tensor(new_label)\n",
    "                if torch.cuda.is_available():\n",
    "                    new_label = new_label.cuda()\n",
    "\n",
    "                correct = correct + torch.sum(pred==new_label)\n",
    "            print(\"EPISODE\",i,\":\")\n",
    "            print(\"Accuracy :\", correct/float(len(test_set)))\n",
    "\n",
    "    return emb, RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = Attribute(\"Animals_with_Attributes2/\")\n",
    "train_set, test_set = load_split(\"Animals_with_Attributes2-2/Features/ResNet101/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is on\n",
      "EPISODE 0 :\n",
      "Accuracy : tensor(0.1867, device='cuda:0')\n",
      "EPISODE 400 :\n",
      "Accuracy : tensor(0.1874, device='cuda:0')\n",
      "EPISODE 800 :\n",
      "Accuracy : tensor(0.3962, device='cuda:0')\n",
      "EPISODE 1200 :\n",
      "Accuracy : tensor(0.6139, device='cuda:0')\n",
      "EPISODE 1600 :\n",
      "Accuracy : tensor(0.7166, device='cuda:0')\n",
      "EPISODE 2000 :\n",
      "Accuracy : tensor(0.7386, device='cuda:0')\n",
      "EPISODE 2400 :\n",
      "Accuracy : tensor(0.7472, device='cuda:0')\n",
      "EPISODE 2800 :\n",
      "Accuracy : tensor(0.7443, device='cuda:0')\n",
      "EPISODE 3200 :\n",
      "Accuracy : tensor(0.7422, device='cuda:0')\n",
      "EPISODE 3600 :\n",
      "Accuracy : tensor(0.7692, device='cuda:0')\n",
      "EPISODE 4000 :\n",
      "Accuracy : tensor(0.7509, device='cuda:0')\n",
      "EPISODE 4400 :\n",
      "Accuracy : tensor(0.7579, device='cuda:0')\n",
      "EPISODE 4800 :\n",
      "Accuracy : tensor(0.7387, device='cuda:0')\n",
      "EPISODE 5200 :\n",
      "Accuracy : tensor(0.7675, device='cuda:0')\n",
      "EPISODE 5600 :\n",
      "Accuracy : tensor(0.7259, device='cuda:0')\n",
      "EPISODE 6000 :\n",
      "Accuracy : tensor(0.7141, device='cuda:0')\n",
      "EPISODE 6400 :\n",
      "Accuracy : tensor(0.7203, device='cuda:0')\n",
      "EPISODE 6800 :\n",
      "Accuracy : tensor(0.7319, device='cuda:0')\n",
      "EPISODE 7200 :\n",
      "Accuracy : tensor(0.7365, device='cuda:0')\n",
      "EPISODE 7600 :\n",
      "Accuracy : tensor(0.7113, device='cuda:0')\n",
      "EPISODE 8000 :\n",
      "Accuracy : tensor(0.7066, device='cuda:0')\n",
      "EPISODE 8400 :\n",
      "Accuracy : tensor(0.6937, device='cuda:0')\n",
      "EPISODE 8800 :\n",
      "Accuracy : tensor(0.7125, device='cuda:0')\n",
      "EPISODE 9200 :\n",
      "Accuracy : tensor(0.7146, device='cuda:0')\n",
      "EPISODE 9600 :\n",
      "Accuracy : tensor(0.7123, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trained_emb, trained_RN = train(attribute, train_set, test_set, lr=0.00001,EPISODE_NUM=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
